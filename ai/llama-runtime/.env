#모델 이름, 토큰 같은 환경변수 저장

# vLLM 서버가 노출할 포트
LLM_API_PORT=8000

# 사용할 모델 (토큰/권한 없으면 아래 줄을 Mistral로 잠시 교체)
LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
# LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3

# (선택) 허깅페이스 액세스 토큰: 없으면 빈칸 허용
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxx
